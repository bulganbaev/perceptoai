import cv2
import os
import numpy as np
from collections import deque
from scipy.optimize import linear_sum_assignment
from cam.camera_driver import StereoCameraSystem
from processing.hailo_detection import HailoInference, Processor


def filter_people(results):
    """
    –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –¥–µ—Ç–µ–∫—Ü–∏–π –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∞.
    –ó–¥–µ—Å—å –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –æ–±—ä–µ–∫—Ç—ã —Å class_id==0 (–Ω–∞–ø—Ä–∏–º–µ—Ä, —á–µ–ª–æ–≤–µ–∫).
    """
    filtered_boxes = []
    filtered_scores = []
    filtered_classes = []

    for i, class_id in enumerate(results['detection_classes']):
        if class_id == 0:
            filtered_boxes.append(results['absolute_boxes'][i])
            filtered_scores.append(results['detection_scores'][i])
            filtered_classes.append(class_id)

    if not filtered_boxes:
        print("–õ–æ–≥: –í —Ç–µ–∫—É—â–µ–º –∫–∞–¥—Ä–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –æ–±—ä–µ–∫—Ç–æ–≤ –∫–ª–∞—Å—Å–∞ 0 (—á–µ–ª–æ–≤–µ–∫).")

    results.update({
        'absolute_boxes': filtered_boxes,
        'detection_classes': filtered_classes,
        'detection_scores': filtered_scores
    })
    return results


def choose_model():
    """
    –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏.
    """
    models_dir = "data/models"
    model_files = [f for f in os.listdir(models_dir) if f.endswith(".hef")]

    if not model_files:
        print("–õ–æ–≥: –ú–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏", models_dir)
        exit(1)

    print("\nüìå –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏:")
    for i, model in enumerate(model_files):
        print(f"  {i + 1}. {model}")

    while True:
        try:
            choice = int(input("\nüëâ –í—ã–±–µ—Ä–∏—Ç–µ –Ω–æ–º–µ—Ä –º–æ–¥–µ–ª–∏: ")) - 1
            if 0 <= choice < len(model_files):
                return os.path.join(models_dir, model_files[choice])
            else:
                print("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –≤–≤–æ–¥. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞.")
        except ValueError:
            print("‚ùå –í–≤–µ–¥–∏—Ç–µ —á–∏—Å–ª–æ!")


# === 1. –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø ===
model_path = choose_model()
inf = HailoInference(model_path)
proc = Processor(inf, conf=0.5)
stereo = StereoCameraSystem()
stereo.start()

# –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Ä–µ–∫—Ç–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –æ–¥–∏–Ω —Ä–∞–∑ (–ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∫–∞–¥—Ä–µ)
rect_params_computed = False
stereo_matcher = cv2.StereoSGBM_create(
    minDisparity=0,
    numDisparities=64,
    blockSize=9,
    P1=8 * 3 * 9 ** 2,
    P2=32 * 3 * 9 ** 2,
    disp12MaxDiff=1,
    uniquenessRatio=10,
    speckleWindowSize=100,
    speckleRange=32
)

print("üé• –ó–∞–ø—É—Å–∫ —Å—Ç–µ—Ä–µ–æ–ø–æ—Ç–æ–∫–∞. –ù–∞–∂–º–∏—Ç–µ 'q' –¥–ª—è –≤—ã—Ö–æ–¥–∞.")

try:
    while True:
        frame_left, frame_right = stereo.get_synchronized_frames()

        if frame_left is not None and frame_right is not None:
            # –î–µ—Ç–µ–∫—Ü–∏—è –æ–±—ä–µ–∫—Ç–æ–≤ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö
            segmentations = proc.process([frame_left, frame_right])

            # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Ç–æ–ª—å–∫–æ –æ–±—ä–µ–∫—Ç–æ–≤ –Ω—É–∂–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, —á–µ–ª–æ–≤–µ–∫)
            # segmentations = [filter_people(result) for result in segmentations]

            # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            for i, frame in enumerate([frame_left, frame_right]):
                for box in segmentations[i]['absolute_boxes']:
                    y1, x1, y2, x2 = box
                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)

                for mask in segmentations[i].get('absolute_masks', []):
                    mask_overlay = np.zeros_like(frame)
                    mask_overlay[:, :, 2] = mask * 255  # –°–∏–Ω–∏–π –∫–∞–Ω–∞–ª –¥–ª—è –º–∞—Å–∫–∏
                    blended = cv2.addWeighted(frame, 0.7, mask_overlay, 0.3, 0)
                    cv2.imshow(f"Segmentation {i}", blended)

            # === –†–ï–ö–¢–ò–§–ò–ö–ê–¶–ò–Ø (–û–¥–∏–Ω —Ä–∞–∑) ===
            if not rect_params_computed:
                print("‚öôÔ∏è –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Ä–µ–∫—Ç–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤...")
                R1, R2, P1, P2, Q = stereo.compute_rectification_maps()
                rect_params_computed = True

            # === –í–´–ß–ò–°–õ–ï–ù–ò–ï –î–ò–°–ü–ê–†–ê–¢–ù–û–°–¢–ò ===
            gray_left = cv2.cvtColor(frame_left, cv2.COLOR_BGR2GRAY)
            gray_right = cv2.cvtColor(frame_right, cv2.COLOR_BGR2GRAY)

            disparity = stereo_matcher.compute(gray_left, gray_right).astype(np.float32) / 16.0

            # –ú–∞—Å–∫–∞ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –Ω–µ–≤–∞–ª–∏–¥–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
            valid_mask = disparity > 0

            # === –û–¶–ï–ù–ö–ê –ì–õ–£–ë–ò–ù–´ (–ø—Ä–∏–º–µ—Ä–Ω–∞—è) ===
            focal_length = P1[0, 0]  # –§–æ–∫—É—Å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –∏–∑ –º–∞—Ç—Ä–∏—Ü—ã P1
            baseline = 0.1  # –ë–∞–∑–∏—Å (—Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É –∫–∞–º–µ—Ä–∞–º–∏ –≤ –º–µ—Ç—Ä–∞—Ö)
            depth_map = np.zeros_like(disparity, dtype=np.float32)
            depth_map[valid_mask] = (focal_length * baseline) / (disparity[valid_mask] + 1e-6)

            # === –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø –ì–õ–£–ë–ò–ù–´ ===
            depth_visual = cv2.normalize(depth_map, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)
            cv2.applyColorMap(depth_visual, cv2.COLORMAP_JET)

            cv2.imshow("Depth Map", depth_visual)
            cv2.imshow("Disparity", cv2.normalize(disparity, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U))

        # –í—ã—Ö–æ–¥ –ø—Ä–∏ –Ω–∞–∂–∞—Ç–∏–∏ 'q'
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

except KeyboardInterrupt:
    print("‚èπÔ∏è –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–æ—Ç–æ–∫–∞...")

# === –û–ß–ò–°–¢–ö–ê –†–ï–°–£–†–°–û–í ===
stereo.stop()
cv2.destroyAllWindows()
print("‚úÖ –ü–æ—Ç–æ–∫ –∑–∞–≤–µ—Ä—à—ë–Ω.")
