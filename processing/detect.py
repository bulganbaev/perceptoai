import cv2
import numpy as np
import os
import time
import hailo_platform as hp

class DepthEstimator:
    def __init__(self, calib_path="data/calibration/calibration_data.npz", use_hailo=True,
                 hef_path="data/models/yolov11s.hef"):
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏
        calib_data = np.load(calib_path)
        self.mtxL, self.distL = calib_data["mtxL"], calib_data["distL"]
        self.mtxR, self.distR = calib_data["mtxR"], calib_data["distR"]
        self.R, self.T = calib_data["R"], calib_data["T"]

        self.R1, self.R2, self.P1, self.P2, self.Q, _, _ = cv2.stereoRectify(
            self.mtxL, self.distL, self.mtxR, self.distR, (1920, 1080), self.R, self.T, alpha=1)

        self.mapL1, self.mapL2 = cv2.initUndistortRectifyMap(self.mtxL, self.distL, self.R1, self.P1, (1920, 1080), cv2.CV_16SC2)
        self.mapR1, self.mapR2 = cv2.initUndistortRectifyMap(self.mtxR, self.distR, self.R2, self.P2, (1920, 1080), cv2.CV_16SC2)

        self.model_w, self.model_h = 640, 640
        self.use_hailo = use_hailo
        if use_hailo:
            self.vdevice = hp.VDevice()
            self.hef = hp.HEF(hef_path)
            configure_params = hp.ConfigureParams.create_from_hef(self.hef, interface=hp.HailoStreamInterface.PCIe)
            self.network_groups = self.vdevice.configure(self.hef, configure_params)
            self.configured_network = self.network_groups[0]

            self.input_vstream_infos = self.configured_network.get_input_vstream_infos()
            self.output_vstream_infos = self.configured_network.get_output_vstream_infos()

            self.input_vstreams_params = hp.InputVStreamParams.make_from_network_group(self.configured_network)
            self.output_vstreams_params = hp.OutputVStreamParams.make_from_network_group(self.configured_network,
                                                                                         format_type=hp.FormatType.FLOAT32)

            self.infer_vstreams = hp.InferVStreams(self.configured_network, self.input_vstreams_params,
                                                   self.output_vstreams_params)

            print("‚úÖ Hailo-8 —É—Å–ø–µ—à–Ω–æ –ø–æ–¥–∫–ª—é—á–µ–Ω. YOLO11s –∑–∞–≥—Ä—É–∂–µ–Ω.")

    def preprocess_stereo(self, imgL, imgR):
        """
        –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ —Ü–µ–Ω—Ç—Ä–∏—Ä—É–µ—Ç –∏—Ö –Ω–∞ —á–µ—Ä–Ω–æ–º —Ñ–æ–Ω–µ.
        """
        def resize_and_pad(image):
            img_h, img_w, _ = image.shape
            scale = min(self.model_w / img_w, self.model_h / img_h)
            new_img_w, new_img_h = int(img_w * scale), int(img_h * scale)
            image_resized = cv2.resize(image, (new_img_w, new_img_h))

            padded_image = np.zeros((self.model_h, self.model_w, 3), dtype=np.uint8)
            pasted_w = (self.model_w - new_img_w) // 2
            pasted_h = (self.model_h - new_img_h) // 2
            padded_image[pasted_h:pasted_h + new_img_h, pasted_w:pasted_w + new_img_w, :] = image_resized
            return padded_image

        imgL_padded = resize_and_pad(imgL)
        imgR_padded = resize_and_pad(imgR)

        return imgL_padded, imgR_padded

    import numpy as np

    def detect_objects(self, img):
        """
        –ó–∞–ø—É—Å–∫–∞–µ—Ç –¥–µ—Ç–µ–∫—Ü–∏—é –æ–±—ä–µ–∫—Ç–æ–≤ —á–µ—Ä–µ–∑ YOLO11s –Ω–∞ Hailo –∏ –ø–∞—Ä—Å–∏—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç.
        """
        img_resized = cv2.resize(img, (640, 640))  # –†–∞–∑–º–µ—Ä –≤—Ö–æ–¥–∞ –¥–ª—è YOLO
        img_resized = np.ascontiguousarray(img_resized.astype(np.uint8)).reshape(1, 640, 640, 3)

        input_data = {"yolov8m_pose/input_layer1": img_resized}

        with self.infer_vstreams as infer_pipeline:
            with self.configured_network.activate():
                output_data = infer_pipeline.infer(input_data)

        print("üìå –î–æ—Å—Ç—É–ø–Ω—ã–µ –≤—ã—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ YOLOv8m-Pose:")
        for key, value in output_data.items():
            print(f" - {key}: shape={value.shape if isinstance(value, np.ndarray) else 'unknown'}")

        return None

    def compute_detection(self, imgL_path, imgR_path):
        start_time = time.time()

        imgL = cv2.imread(imgL_path)
        imgR = cv2.imread(imgR_path)

        if imgL is None or imgR is None:
            raise ValueError("–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π! –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—É—Ç–∏.")

        # ‚úÖ –î–µ–ª–∞–µ–º —Ä–µ–∫—Ç–∏—Ñ–∏–∫–∞—Ü–∏—é
        imgL_rect = cv2.remap(imgL, self.mapL1, self.mapL2, cv2.INTER_LINEAR)
        imgR_rect = cv2.remap(imgR, self.mapR1, self.mapR2, cv2.INTER_LINEAR)

        # ‚úÖ –ü—Ä–∏–º–µ–Ω—è–µ–º –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ —Ü–µ–Ω—Ç—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ
        imgL_padded, imgR_padded = self.preprocess_stereo(imgL_rect, imgR_rect)

        # ‚úÖ –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ—Å–ª–µ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
        cv2.imwrite("data/images/processed_left.png", imgL_padded)
        cv2.imwrite("data/images/processed_right.png", imgR_padded)
        print("‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω—ã –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: processed_left.png, processed_right.png")

        # ‚úÖ –ó–∞–ø—É—Å–∫–∞–µ–º YOLO –Ω–∞ –æ–±–µ–∏—Ö –∫–∞–º–µ—Ä–∞—Ö
        detections_left = self.detect_objects(imgL_padded)
        detections_right = self.detect_objects(imgR_padded)

        # ‚úÖ –†–∏—Å—É–µ–º bounding box'—ã
        for det in detections_left:
            x1, y1, x2, y2, score, cls = det
            cv2.rectangle(imgL_padded, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)
            cv2.putText(imgL_padded, f"ID:{int(cls)} {score:.2f}", (int(x1), int(y1 - 10)),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

        for det in detections_right:
            x1, y1, x2, y2, score, cls = det
            cv2.rectangle(imgR_padded, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)
            cv2.putText(imgR_padded, f"ID:{int(cls)} {score:.2f}", (int(x1), int(y1 - 10)),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

        # ‚úÖ –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –¥–µ—Ç–µ–∫—Ü–∏–µ–π
        cv2.imwrite("data/images/detected_left.png", imgL_padded)
        cv2.imwrite("data/images/detected_right.png", imgR_padded)
        print("‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–µ—Ç–µ–∫—Ü–∏–∏: detected_left.png, detected_right.png")

        elapsed_time = time.time() - start_time
        print(f"‚è± –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {elapsed_time:.4f} —Å–µ–∫")


if __name__ == "__main__":
    detector = DepthEstimator(use_hailo=True)
    detector.compute_detection("data/images/left/left_00.jpg", "data/images/right/right_00.jpg")
