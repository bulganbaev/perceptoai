import cv2
import os
import numpy as np
from collections import deque
from scipy.optimize import linear_sum_assignment  # Hungarian Algorithm
from cam.camera_driver import CameraDriver
from processing.hailo_detection import HailoInference, Processor

# === 1. –ó–ê–ì–†–£–ó–ö–ê –ü–ê–†–ê–ú–ï–¢–†–û–í –ö–ê–õ–ò–ë–†–û–í–ö–ò ===
calib_data = np.load("data/calibration/calibration_data.npz")

mtxL = calib_data["mtxL"]
distL = calib_data["distL"]
mtxR = calib_data["mtxR"]
distR = calib_data["distR"]
R = calib_data["R"]
T = calib_data["T"]

BASELINE = abs(T[0][0])  # –†–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É –∫–∞–º–µ—Ä–∞–º–∏ (–º–º)
FOCAL_LENGTH = mtxL[0, 0]  # –§–æ–∫—É—Å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –≤ –ø–∏–∫—Å–µ–ª—è—Ö

print(f"üîß –ó–∞–≥—Ä—É–∑–∫–∞ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏: baseline={BASELINE:.2f}mm, focal={FOCAL_LENGTH:.2f}px")

# === 2. –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –§–ò–õ–¨–¢–†–ê –ì–õ–£–ë–ò–ù–´ ===
depth_history = {}
DEPTH_FILTER_SIZE = 5  # –†–∞–∑–º–µ—Ä —Ñ–∏–ª—å—Ç—Ä–∞


def undistort_and_rectify(frame, mtx, dist):
    """–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∏—Å–∫–∞–∂–µ–Ω–∏–π –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏."""
    h, w = frame.shape[:2]
    new_mtx, roi = cv2.getOptimalNewCameraMatrix(mtx, dist, (w, h), 1, (w, h))
    return cv2.undistort(frame, mtx, dist, None, new_mtx)


def compute_disparity_map(left_img, right_img):
    """–†–∞—Å—Å—á–µ—Ç –∫–∞—Ä—Ç—ã –≥–ª—É–±–∏–Ω—ã —á–µ—Ä–µ–∑ disparity."""
    gray_left = cv2.cvtColor(left_img, cv2.COLOR_BGR2GRAY)
    gray_right = cv2.cvtColor(right_img, cv2.COLOR_BGR2GRAY)

    stereo = cv2.StereoBM_create(numDisparities=64, blockSize=15)
    disparity = stereo.compute(gray_left, gray_right).astype(np.float32)

    disparity[disparity <= 0] = 1  # –ò–∑–±–µ–≥–∞–µ–º –¥–µ–ª–µ–Ω–∏—è –Ω–∞ 0
    depth_map = (FOCAL_LENGTH * BASELINE) / disparity  # –ì–ª—É–±–∏–Ω–∞ –ø–æ disparity

    return depth_map


def match_boxes(left_results, right_results):
    """–°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ bounding box'–æ–≤ –ø–æ —Ü–µ–Ω—Ç—Ä–∞–º –∏ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª–∏."""
    left_boxes = left_results["absolute_boxes"]
    right_boxes = right_results["absolute_boxes"]

    if not left_boxes or not right_boxes:
        return []

    left_centers = np.array([(x1 + x2) // 2 for (_, x1, _, x2) in left_boxes])
    right_centers = np.array([(x1 + x2) // 2 for (_, x1, _, x2) in right_boxes])

    cost_matrix = np.abs(left_centers[:, None] - right_centers[None, :])

    left_indices, right_indices = linear_sum_assignment(cost_matrix)
    matches = [(l, r) for l, r in zip(left_indices, right_indices)]

    return matches


def compute_depth(left_results, right_results, matches, depth_map):
    """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –≥–ª—É–±–∏–Ω—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ disparity + –º–µ–¥–∏–∞–Ω–Ω—ã–π —Ñ–∏–ª—å—Ç—Ä depth map."""
    global depth_history
    depths = {}
    left_boxes = left_results['absolute_boxes']
    right_boxes = right_results['absolute_boxes']

    for left_idx, right_idx in matches:
        left_box = left_boxes[left_idx]
        right_box = right_boxes[right_idx]

        left_center_x = (left_box[1] + left_box[3]) // 2
        right_center_x = (right_box[1] + right_box[3]) // 2

        disparity = max(1, abs(left_center_x - right_center_x))  # –ò–∑–±–µ–≥–∞–µ–º –¥–µ–ª–µ–Ω–∏—è –Ω–∞ 0
        raw_depth = (FOCAL_LENGTH * BASELINE) / disparity

        x1, y1, x2, y2 = left_box
        box_depth_values = depth_map[y1:y2, x1:x2]
        box_depth_values = box_depth_values[box_depth_values > 0]

        if len(box_depth_values) > 0:
            filtered_depth = np.median(box_depth_values)
        else:
            filtered_depth = raw_depth

        obj_id = left_idx
        if obj_id not in depth_history:
            depth_history[obj_id] = deque(maxlen=DEPTH_FILTER_SIZE)

        depth_history[obj_id].append(filtered_depth)
        final_depth = np.median(depth_history[obj_id])

        depths[obj_id] = (left_box[1], left_box[0], final_depth)

    return list(depths.values())


def filter_objects(results):
    """–û—Å—Ç–∞–≤–ª—è–µ—Ç —Ç–æ–ª—å–∫–æ –æ–±—ä–µ–∫—Ç—ã —Å class_id == 0 (—á–µ–ª–æ–≤–µ–∫)."""
    filtered_boxes = []
    filtered_scores = []
    filtered_classes = []

    for i, class_id in enumerate(results['detection_classes']):
        if class_id == 0:  # –¢–æ–ª—å–∫–æ —á–µ–ª–æ–≤–µ–∫
            filtered_boxes.append(results['absolute_boxes'][i])
            filtered_scores.append(results['detection_scores'][i])
            filtered_classes.append(class_id)

    results.update({
        'absolute_boxes': filtered_boxes,
        'detection_classes': filtered_classes,
        'detection_scores': filtered_scores
    })


def draw_boxes(image, results, color=(0, 255, 0)):
    """–û—Ç—Ä–∏—Å–æ–≤–∫–∞ bbox."""
    for (y1, x1, y2, x2), class_id, score in zip(results['absolute_boxes'], results['detection_classes'],
                                                 results['detection_scores']):
        label = f"Person ({score:.2f})"
        cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)
        cv2.putText(image, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)
    return image


def draw_depth(image, depth_results):
    """–û—Ç—Ä–∏—Å–æ–≤–∫–∞ –≥–ª—É–±–∏–Ω—ã –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏."""
    for x, y, d in depth_results:
        cv2.putText(image, f"Depth: {d:.1f} mm", (x, y), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 3)
    return image


# === 3. –ó–ê–ü–£–°–ö –ö–ê–ú–ï–† –ò –ú–û–î–ï–õ–ò ===
inf = HailoInference("data/models/yolov11s.hef")
proc = Processor(inf, conf=0.5)

cam_left = CameraDriver(camera_id=0)
cam_right = CameraDriver(camera_id=1)
cam_left.start_camera()
cam_right.start_camera()

print("üé• –ó–∞–ø—É—Å–∫ —Å—Ç–µ—Ä–µ–æ–ø–æ—Ç–æ–∫–∞ —Å —Ä–∞—Å—á–µ—Ç–æ–º –≥–ª—É–±–∏–Ω—ã. –ù–∞–∂–º–∏—Ç–µ 'q' –¥–ª—è –≤—ã—Ö–æ–¥–∞.")

try:
    while True:
        frame_left = cam_left.get_frame()
        frame_right = cam_right.get_frame()

        if frame_left is not None and frame_right is not None:
            frame_left = undistort_and_rectify(frame_left, mtxL, distL)
            frame_right = undistort_and_rectify(frame_right, mtxR, distR)

            depth_map = compute_disparity_map(frame_left, frame_right)  # –†–∞—Å—á–µ—Ç –∫–∞—Ä—Ç—ã –≥–ª—É–±–∏–Ω—ã

            detections = proc.process([frame_left, frame_right])
            result_left, result_right = detections[0], detections[1]

            filter_objects(result_left)
            filter_objects(result_right)

            matches = match_boxes(result_left, result_right)
            depth_results = compute_depth(result_left, result_right, matches, depth_map)

            processed_left = draw_boxes(frame_left, result_left)
            processed_right = draw_boxes(frame_right, result_right)

            processed_left = draw_depth(processed_left, depth_results)

            combined = cv2.hconcat([processed_left, processed_right])

            cv2.namedWindow("Stereo Depth", cv2.WINDOW_NORMAL)  # –ò–∑–º–µ–Ω—è–µ–º–æ–µ –æ–∫–Ω–æ
            cv2.resizeWindow("Stereo Depth", 1920, 1080)  # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –æ–∫–Ω–∞
            cv2.imshow("Stereo Depth", combined)

        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

except KeyboardInterrupt:
    print("‚èπÔ∏è –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–æ—Ç–æ–∫–∞...")

cam_left.stop_camera()
cam_right.stop_camera()
cv2.destroyAllWindows()
print("‚úÖ –ü–æ—Ç–æ–∫ –∑–∞–≤–µ—Ä—à—ë–Ω.")
