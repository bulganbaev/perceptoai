import cv2
import numpy as np
from cam.camera_driver import CameraDriver
from processing.hailo_detection import HailoInference, Processor

# === 1. –ó–ê–ì–†–£–ó–ö–ê –ü–ê–†–ê–ú–ï–¢–†–û–í –ö–ê–õ–ò–ë–†–û–í–ö–ò ===
calib_data = np.load("data/calibration/calibration_data.npz")

mtxL = calib_data["mtxL"]
distL = calib_data["distL"]
mtxR = calib_data["mtxR"]
distR = calib_data["distR"]
R = calib_data["R"]
T = calib_data["T"]

BASELINE = abs(T[0][0])  # –†–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É –∫–∞–º–µ—Ä–∞–º–∏ (–º–º)
FOCAL_LENGTH = mtxL[0, 0]  # –§–æ–∫—É—Å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –≤ –ø–∏–∫—Å–µ–ª—è—Ö

print(f"üîß –ó–∞–≥—Ä—É–∑–∫–∞ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏: baseline={BASELINE:.2f}mm, focal={FOCAL_LENGTH:.2f}px")


def undistort_and_rectify(frame, mtx, dist):
    """–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∏—Å–∫–∞–∂–µ–Ω–∏–π –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏."""
    h, w = frame.shape[:2]
    new_mtx, roi = cv2.getOptimalNewCameraMatrix(mtx, dist, (w, h), 1, (w, h))
    return cv2.undistort(frame, mtx, dist, None, new_mtx)


def draw_boxes(image, results, color=(0, 255, 0)):
    """–û—Ç—Ä–∏—Å–æ–≤–∫–∞ –±–∞—É–Ω–¥–∏–Ω–≥ –±–æ–∫—Å–æ–≤."""
    for (y1, x1, y2, x2), class_id, score in zip(results['absolute_boxes'], results['detection_classes'],
                                                 results['detection_scores']):
        if class_id == 0:  # –¢–æ–ª—å–∫–æ class=0
            label = f"{class_id} ({score:.2f})"
            cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)
            cv2.putText(image, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
    return image


def match_boxes(left_results, right_results):
    """–°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –æ–±—ä–µ–∫—Ç–æ–≤ –ø–æ –≤—ã—Å–æ—Ç–µ –∏ X-–∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º."""
    matches = []
    left_boxes, right_boxes = left_results['absolute_boxes'], right_results['absolute_boxes']

    for i, (y1_L, x1_L, y2_L, x2_L) in enumerate(left_boxes):
        center_L = ((x1_L + x2_L) // 2, (y1_L + y2_L) // 2)
        best_match, best_distance = None, float('inf')

        for j, (y1_R, x1_R, y2_R, x2_R) in enumerate(right_boxes):
            center_R = ((x1_R + x2_R) // 2, (y1_R + y2_R) // 2)
            y_diff = abs(center_L[1] - center_R[1])  # –†–∞–∑–Ω–∏—Ü–∞ –ø–æ Y
            x_diff = abs(center_L[0] - center_R[0])  # –†–∞–∑–Ω–∏—Ü–∞ –ø–æ X

            if y_diff < 20 and x_diff < best_distance:
                best_distance, best_match = x_diff, j

        if best_match is not None:
            matches.append((i, best_match))

    return matches


def compute_depth(left_results, right_results, matches):
    """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –≥–ª—É–±–∏–Ω—ã –ø–æ –¥–∏—Å–ø–∞—Ä–∏—Ç–∏ —Å —É—á–µ—Ç–æ–º –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏."""
    depths = []
    for i, j in matches:
        center_L = (left_results['absolute_boxes'][i][1] + left_results['absolute_boxes'][i][3]) // 2
        center_R = (right_results['absolute_boxes'][j][1] + right_results['absolute_boxes'][j][3]) // 2

        disparity = abs(center_L - center_R)
        depth = (FOCAL_LENGTH * BASELINE) / disparity if disparity > 0 else float('inf')

        depths.append((center_L, left_results['absolute_boxes'][i][0], depth))

    return depths


# === 2. –ó–ê–ü–£–°–ö –ö–ê–ú–ï–† –ò –î–ï–¢–ï–ö–¶–ò–ò ===
inf = HailoInference('data/models/yolov11s.hef')
proc = Processor(inf, conf=0.5)

cam_left = CameraDriver(camera_id=0)
cam_right = CameraDriver(camera_id=1)
cam_left.start_camera()
cam_right.start_camera()

print("üé• –ó–∞–ø—É—Å–∫ —Å—Ç–µ—Ä–µ–æ–ø–æ—Ç–æ–∫–∞ —Å —Ä–∞—Å—á–µ—Ç–æ–º –≥–ª—É–±–∏–Ω—ã. –ù–∞–∂–º–∏—Ç–µ 'q' –¥–ª—è –≤—ã—Ö–æ–¥–∞.")

try:
    while True:
        frame_left = cam_left.get_frame()
        frame_right = cam_right.get_frame()

        if frame_left is not None and frame_right is not None:
            # === 3. –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –∏—Å–∫–∞–∂–µ–Ω–∏—è ===
            frame_left = undistort_and_rectify(frame_left, mtxL, distL)
            frame_right = undistort_and_rectify(frame_right, mtxR, distR)

            # === 4. –ó–∞–ø—É—Å–∫–∞–µ–º –¥–µ—Ç–µ–∫—Ü–∏—é ===
            detections = proc.process([frame_left, frame_right])
            result_left, result_right = detections[0], detections[1]

            # === 5. –°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ–º –æ–±—ä–µ–∫—Ç—ã ===
            matches = match_boxes(result_left, result_right)

            # === 6. –í—ã—á–∏—Å–ª—è–µ–º –≥–ª—É–±–∏–Ω—É ===
            depth_results = compute_depth(result_left, result_right, matches)

            # === 7. –û—Ç—Ä–∏—Å–æ–≤–∫–∞ –±–æ–∫—Å–æ–≤ –∏ –≥–ª—É–±–∏–Ω—ã ===
            processed_left = draw_boxes(frame_left, result_left, color=(0, 255, 0))
            processed_right = draw_boxes(frame_right, result_right, color=(255, 0, 0))

            for x, y, d in depth_results:
                cv2.putText(processed_left, f"Depth: {d:.1f} mm", (x, y), cv2.FONT_HERSHEY_SIMPLEX, 2,
                            (255, 255, 255), 2)
                cv2.putText(processed_right, f"Depth: {d:.1f} mm", (x, y), cv2.FONT_HERSHEY_SIMPLEX, 2,
                            (255, 255, 255), 2)

            # === 8. –í—ã–≤–æ–¥ ===
            combined = cv2.hconcat([processed_left, processed_right])
            cv2.namedWindow("Stereo Depth", cv2.WINDOW_NORMAL)
            cv2.resizeWindow("Stereo Depth", 1920, 1080)
            cv2.imshow("Stereo Depth", combined)

        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

except KeyboardInterrupt:
    print("‚èπÔ∏è –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–æ—Ç–æ–∫–∞...")

# === 9. –ó–∞–≤–µ—Ä—à–∞–µ–º —Ä–∞–±–æ—Ç—É –∫–∞–º–µ—Ä ===
cam_left.stop_camera()
cam_right.stop_camera()
cv2.destroyAllWindows()
print("‚úÖ –ü–æ—Ç–æ–∫ –∑–∞–≤–µ—Ä—à—ë–Ω.")
